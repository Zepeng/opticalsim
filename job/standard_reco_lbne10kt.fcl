#include "job/services_lbne.fcl"
#include "job/caldata_lbne.fcl"
#include "job/cluster_lbne.fcl"
#include "job/trackfindermodules.fcl"

process_name: Reco

services:
{
  # Load the service that manages root files for histograms.
  TFileService: { fileName: "reco10kt_hist.root" }
  Timing:       {}
  RandomNumberGenerator: {} #ART native random number generator
  message:      @local::standard_warning
  user:         @local::lbne10kt_services 	     
}


#source is now a root file
source:
{
  module_type: RootInput
  maxEvents:  -1        # Number of events to create
}

# Define and configure some modules to do work on each event.
# First modules are defined; they are scheduled later.
# Modules are grouped by type.
physics:
{

 producers:
 {
  calgaus:    @local::lbne10kt_calgaushf
  caldata:    @local::lbne10kt_calwire
  gaushit:    @local::lbne10kt_gaushitfinder
  apacheat:   @local::standard_disambigcheat
  ffthit:     @local::lbne10kt_hitfinder
  dbcluster:  @local::lbne10kt_dbcluster
  fuzzy:      @local::lbne10kt_fuzzycluster
  hough:      @local::standard_houghlinefinder
 }
  
 analyzers:
 {
  gausana:      @local::gaus_hitfinderana
  dbclusterana: @local::lbne10kt_dbclusterana
 }

 reco:    [ caldata, gaushit, apacheat ]
 ana:  [  ]

 stream1:  [ out1 ]

 trigger_paths: [ reco ] 

 end_paths:     [ ana, stream1]  
}

#block to define where the output goes.  if you defined a filter in the physics
#block and put it in the trigger_paths then you need to put a SelectEvents: {SelectEvents: [XXX]}
#entry in the output stream you want those to go to, where XXX is the label of the filter module(s)
outputs:
{
 out1:
 {
   module_type: RootOutput
   fileName:    "reco_lbne10kt.root" #default file name, can override from command line with -o or --output
#   outputCommands: [ "keep *", "drop *_caldata_*_*" ]
 }
}

